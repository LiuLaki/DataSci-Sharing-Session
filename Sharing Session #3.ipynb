{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs6BAr1Q7-fc"
   },
   "source": [
    "# Deep Dive in Anomaly Detection with Deep Learning\n",
    "**Cyber Data Science Sharing Session #3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cgtE_Cnzhf7s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_cOXmiWj_Az"
   },
   "source": [
    "### 1) Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data we used is simulated for **Window Event 4624**, which records each logon event. Actually, ADX Data Lake collects data once one logon happened, which means **each row is one event**.  \n",
    "- However, to catch suspicious attacker, we need to aggregate the ADX data on the user level. \n",
    "- Depending on the event characertics or the project objective, the aggregation can be done on the hour level or day level. For this demo, the data is **aggregated on the daily basis**.\n",
    "- Here, We only take the data for **one user**. Also, only some of the columns are selected for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edgZZr8fjKoj",
    "outputId": "c458a378-163f-4a1a-eaa4-6231cef0799e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>nb_ip</th>\n",
       "      <th>avg_time_interval</th>\n",
       "      <th>nb_logon</th>\n",
       "      <th>nb_event_categories</th>\n",
       "      <th>nb_domain</th>\n",
       "      <th>nb_fail_logon</th>\n",
       "      <th>nb_programs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-07-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-07-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-07-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-07-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2010-11-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2010-11-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  nb_ip  avg_time_interval  nb_logon  nb_event_categories  \\\n",
       "0    2009-07-15    0.0                0.0     242.0                  2.0   \n",
       "1    2009-07-16    0.0                0.0     242.0                  2.0   \n",
       "2    2009-07-17    1.0                0.0     242.0                  2.0   \n",
       "3    2009-07-18    1.0                0.0     242.0                  3.0   \n",
       "4    2009-07-19    1.0                0.0     242.0                  4.0   \n",
       "..          ...    ...                ...       ...                  ...   \n",
       "495  2010-11-22    1.0                0.0     240.0                  6.0   \n",
       "496  2010-11-23    1.0                0.0     241.0                  5.0   \n",
       "497  2010-11-24    1.0                0.0     240.0                  5.0   \n",
       "498  2010-11-25    1.0                0.0     242.0                  4.0   \n",
       "499  2010-11-26    1.0                0.0     240.0                  5.0   \n",
       "\n",
       "     nb_domain  nb_fail_logon  nb_programs  \n",
       "0          1.0            1.0          4.0  \n",
       "1          0.0            1.0          3.0  \n",
       "2          0.0            0.0          5.0  \n",
       "3          0.0            0.0          4.0  \n",
       "4          0.0            0.0          4.0  \n",
       "..         ...            ...          ...  \n",
       "495        3.0            1.0          7.0  \n",
       "496        1.0            0.0          5.0  \n",
       "497        1.0            2.0          8.0  \n",
       "498        1.0            0.0          4.0  \n",
       "499        1.0            0.0          8.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df = pd.read_csv('https://raw.githubusercontent.com/LiuLaki/DataSci-Sharing-Session/main/user_data.csv')\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_cOXmiWj_Az"
   },
   "source": [
    "### 2) Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Cleaning : Deep Learning Neural Network models **only accept numrical data**. All the data in forms of string, text, date time should be transformed into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_ip</th>\n",
       "      <th>avg_time_interval</th>\n",
       "      <th>nb_logon</th>\n",
       "      <th>nb_event_categories</th>\n",
       "      <th>nb_domain</th>\n",
       "      <th>nb_fail_logon</th>\n",
       "      <th>nb_programs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_ip  avg_time_interval  nb_logon  nb_event_categories  \\\n",
       "datetime                                                              \n",
       "2009-07-15    0.0                0.0     242.0                  2.0   \n",
       "2009-07-16    0.0                0.0     242.0                  2.0   \n",
       "2009-07-17    1.0                0.0     242.0                  2.0   \n",
       "2009-07-18    1.0                0.0     242.0                  3.0   \n",
       "2009-07-19    1.0                0.0     242.0                  4.0   \n",
       "...           ...                ...       ...                  ...   \n",
       "2010-11-22    1.0                0.0     240.0                  6.0   \n",
       "2010-11-23    1.0                0.0     241.0                  5.0   \n",
       "2010-11-24    1.0                0.0     240.0                  5.0   \n",
       "2010-11-25    1.0                0.0     242.0                  4.0   \n",
       "2010-11-26    1.0                0.0     240.0                  5.0   \n",
       "\n",
       "            nb_domain  nb_fail_logon  nb_programs  \n",
       "datetime                                           \n",
       "2009-07-15        1.0            1.0          4.0  \n",
       "2009-07-16        0.0            1.0          3.0  \n",
       "2009-07-17        0.0            0.0          5.0  \n",
       "2009-07-18        0.0            0.0          4.0  \n",
       "2009-07-19        0.0            0.0          4.0  \n",
       "...               ...            ...          ...  \n",
       "2010-11-22        3.0            1.0          7.0  \n",
       "2010-11-23        1.0            0.0          5.0  \n",
       "2010-11-24        1.0            2.0          8.0  \n",
       "2010-11-25        1.0            0.0          4.0  \n",
       "2010-11-26        1.0            0.0          8.0  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df = daily_df.set_index('datetime')\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to split the overall dataset into two parts - train and test. We will use train data to train the Deep Learning models, and use the test dataset to see the performance. **The objective is to make sure the model we trained can be generalised to other dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((374, 7), (125, 7))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Ratio : 75% of Data to train, 25% of Data to test\n",
    "thres = int(daily_df.shape[0]*0.75)\n",
    "train_df,test_df = daily_df[1:thres], daily_df[thres:]\n",
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Scaling : MinMax Scaler\n",
    "\n",
    "- Reasons : Deep Neural Networks are **very sentitive to the number scale**. To minimize the error, we should scale all the data in the specific range by different types of scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57076/1434863843.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/tmp/ipykernel_57076/1434863843.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n"
     ]
    }
   ],
   "source": [
    "train = train_df\n",
    "scalers={}\n",
    "\n",
    "for i in train_df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+ i] = scaler\n",
    "    train[i]=s_s\n",
    "\n",
    "test = test_df\n",
    "for i in train_df.columns:\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+i] = scaler\n",
    "    test[i]=s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_ip</th>\n",
       "      <th>avg_time_interval</th>\n",
       "      <th>nb_logon</th>\n",
       "      <th>nb_event_categories</th>\n",
       "      <th>nb_domain</th>\n",
       "      <th>nb_fail_logon</th>\n",
       "      <th>nb_programs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-18</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-19</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-20</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-21</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-22</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-23</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-24</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_ip  avg_time_interval  nb_logon  nb_event_categories  \\\n",
       "datetime                                                              \n",
       "2009-07-16    0.0                0.0  0.545455             0.000000   \n",
       "2009-07-17    0.5                0.0  0.545455             0.000000   \n",
       "2009-07-18    0.5                0.0  0.545455             0.166667   \n",
       "2009-07-19    0.5                0.0  0.545455             0.333333   \n",
       "2009-07-20    0.0                0.0  0.545455             0.000000   \n",
       "...           ...                ...       ...                  ...   \n",
       "2010-07-20    0.5                0.0  0.545455             0.166667   \n",
       "2010-07-21    0.5                0.0  0.545455             0.166667   \n",
       "2010-07-22    0.5                0.0  0.454545             0.333333   \n",
       "2010-07-23    0.5                0.0  0.363636             0.333333   \n",
       "2010-07-24    0.5                0.0  0.363636             0.166667   \n",
       "\n",
       "            nb_domain  nb_fail_logon  nb_programs  \n",
       "datetime                                           \n",
       "2009-07-16      0.000       0.166667     0.071429  \n",
       "2009-07-17      0.000       0.000000     0.214286  \n",
       "2009-07-18      0.000       0.000000     0.142857  \n",
       "2009-07-19      0.000       0.000000     0.142857  \n",
       "2009-07-20      0.125       0.166667     0.071429  \n",
       "...               ...            ...          ...  \n",
       "2010-07-20      0.000       0.000000     0.142857  \n",
       "2010-07-21      0.125       0.000000     0.142857  \n",
       "2010-07-22      0.000       0.166667     0.142857  \n",
       "2010-07-23      0.125       0.166667     0.285714  \n",
       "2010-07-24      0.000       0.166667     0.071429  \n",
       "\n",
       "[374 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_cOXmiWj_Az"
   },
   "source": [
    "### 3) LSTM Model Preparation : Sequence Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall LSTM : **Long Short Term Memory (LSTM)** is one type of **Recurrent Neural Network (RNN)**. For a time series data, LSTM can predict the next occurance by **remembering the previous important information** and **forgetting unimportant information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Hyperparameters** mean the parameters that are not a part of models - there is no academical way to set, but there are some data science techniques to help find the most optimal one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Most Import Hyperparameters in LSTM :** the number of sequqnce elements we look back, and the number of sequence elements we are going to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "95DRaJDAiAzj"
   },
   "outputs": [],
   "source": [
    "# For this case, let's assume that\n",
    "# Given past 10 days observation, forecast the next 5 days observations. \n",
    "n_past = 10\n",
    "n_future = 5 \n",
    "n_features = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6axUcusZhvzK"
   },
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "  #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "  #\n",
    "  X, y = list(), list()\n",
    "  for window_start in range(len(series)):\n",
    "    past_end = window_start + n_past\n",
    "    future_end = past_end + n_future\n",
    "    if future_end > len(series):\n",
    "      break\n",
    "    # slicing the past and future parts of the window\n",
    "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "    X.append(past)\n",
    "    y.append(future)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BOHlFWgVidl_"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = split_series(train.values,n_past, n_future)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "\n",
    "X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0rBKOD_8L6j",
    "outputId": "106698f4-5dd5-47b6-aa1d-3430432570a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.54545455, 0.        , 0.        ,\n",
       "        0.16666667, 0.07142857],\n",
       "       [0.5       , 0.        , 0.54545455, 0.        , 0.        ,\n",
       "        0.        , 0.21428571],\n",
       "       [0.5       , 0.        , 0.54545455, 0.16666667, 0.        ,\n",
       "        0.        , 0.14285714],\n",
       "       [0.5       , 0.        , 0.54545455, 0.33333333, 0.        ,\n",
       "        0.        , 0.14285714],\n",
       "       [0.        , 0.        , 0.54545455, 0.        , 0.125     ,\n",
       "        0.16666667, 0.07142857],\n",
       "       [0.5       , 0.        , 0.63636364, 0.16666667, 0.        ,\n",
       "        0.16666667, 0.21428571],\n",
       "       [0.5       , 0.        , 0.54545455, 0.        , 0.        ,\n",
       "        0.        , 0.07142857],\n",
       "       [0.5       , 0.        , 0.54545455, 0.16666667, 0.125     ,\n",
       "        0.        , 0.28571429],\n",
       "       [0.        , 0.        , 0.54545455, 0.        , 0.        ,\n",
       "        0.        , 0.07142857],\n",
       "       [0.        , 0.        , 0.54545455, 0.        , 0.        ,\n",
       "        0.        , 0.07142857]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UsHtSrSP8QNX",
    "outputId": "92bc893c-4e58-470f-d7ca-82c6c0af0232"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.63636364, 0.        , 0.        ,\n",
       "        0.16666667, 0.07142857],\n",
       "       [0.        , 0.        , 0.63636364, 0.        , 0.        ,\n",
       "        0.16666667, 0.14285714],\n",
       "       [0.5       , 0.        , 0.54545455, 0.16666667, 0.        ,\n",
       "        0.5       , 0.07142857],\n",
       "       [0.5       , 0.        , 0.54545455, 0.16666667, 0.125     ,\n",
       "        0.16666667, 0.21428571],\n",
       "       [0.5       , 0.        , 0.54545455, 0.        , 0.        ,\n",
       "        0.33333333, 0.07142857]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bzav_OzQh_Dx",
    "outputId": "921927b5-e3ea-487a-e2ea-01042ec12729",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_cOXmiWj_Az"
   },
   "source": [
    "### 4) LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2rRUBjbnJij"
   },
   "source": [
    "#### 4.1 Model Architecture\n",
    "1. For Deep Learning, **the first step** is to define each layer - which layer to put, and which parameters to set. \n",
    "\n",
    "2. **Then** we can train the model : Here we need to define how to train the model - how many epochs, what are the loss functions, what methods to optimize. This process allows the model to learn from the data. By comparing the results predicted by model and the realilty to get the best model.\n",
    "\n",
    "3. **Last Step** is to use the model we trained, to predict the unknowns. Once We get the results, we can try to interpretate, or post-process them to get the insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we will train **Two Deep Learning LSTM Models**\n",
    "- **Model 1 - E1D1** : Sequence to Sequence Model with one encoder layer and one decoder layer. \n",
    "\n",
    "- **Model 2 - E2D2** : Sequence to Sequence Model with two encoder layers and two decoder layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 14:38:58.316871: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-01 14:39:12.698111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7435 MB memory:  -> device: 0, name: Tesla M60, pci bus id: 0001:00:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent_v2.LSTM at 0x7f64f1552280>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[10, 7] * [7, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMYwUsJ8HAtu",
    "outputId": "fc6fcab4-80c9-4be9-c40e-65622b4eea20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 10:10:02.596339: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-01 10:10:15.281526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7435 MB memory:  -> device: 0, name: Tesla M60, pci bus id: 0001:00:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 100),        43200       ['input_1[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 5, 100)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 5, 100)       80400       ['repeat_vector[0][0]',          \n",
      "                                                                  'lstm[0][1]',                   \n",
      "                                                                  'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 5, 7)        707         ['lstm_1[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,307\n",
      "Trainable params: 124,307\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 1 Definition: E1D1\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,\n",
    "                                                              initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l1)\n",
    "\n",
    "##\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,\n",
    "                                   decoder_outputs1)\n",
    "\n",
    "model_e1d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ze7iac48h1JV",
    "outputId": "f0ca8ed6-9105-4dde-c25e-46e59ba8712b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 10, 100),    43200       ['input_2[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 100),        80400       ['lstm_2[0][0]']                 \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVector)  (None, 5, 100)      0           ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 5, 100)       80400       ['repeat_vector_1[0][0]',        \n",
      "                                                                  'lstm_2[0][1]',                 \n",
      "                                                                  'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 5, 100)       80400       ['lstm_4[0][0]',                 \n",
      "                                                                  'lstm_3[0][1]',                 \n",
      "                                                                  'lstm_3[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 5, 7)        707         ['lstm_5[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 285,107\n",
      "Trainable params: 285,107\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 2 Definition: E2D2\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, \n",
    "                                  return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "\n",
    "\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,\n",
    "                                                              initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,\n",
    "                                                              initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
    "\n",
    "\n",
    "\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,\n",
    "                                   decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q0prbvcnq6W"
   },
   "source": [
    "#### 4.2 Training the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L4Ee4kb5HuzM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 10:10:32.606208: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    }
   ],
   "source": [
    "# Define GPU\n",
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with gpu_strategy.scope():\n",
    "    \n",
    "\n",
    "    # define learning rate\n",
    "    reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "\n",
    "    ######################\n",
    "    ##### Model 1 ########\n",
    "    ######################\n",
    "    # define optimization method\n",
    "    model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                       loss=tf.keras.losses.Huber())\n",
    "    \n",
    "    # define traing method\n",
    "    history_e1d1=model_e1d1.fit(X_train,\n",
    "                                y_train,\n",
    "                                epochs=25,\n",
    "                                validation_data=(X_test,y_test),\n",
    "                                batch_size=32,\n",
    "                                verbose=0,\n",
    "                                callbacks=[reduce_lr])\n",
    "\n",
    "    ######################\n",
    "    ##### Model 2 ########\n",
    "    ######################\n",
    "    # define optimization method\n",
    "    model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                       loss=tf.keras.losses.Huber())\n",
    "    \n",
    "     # define traing method\n",
    "    history_e2d2=model_e2d2.fit(X_train,\n",
    "                                y_train,\n",
    "                                epochs=25,\n",
    "                                validation_data=(X_test,y_test),\n",
    "                                batch_size=32,\n",
    "                                verbose=0,\n",
    "                                callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-w0gYG-oep8"
   },
   "source": [
    "#### 4.3 Checking Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Error Analysis for Model 1\n",
    "\n",
    "plt.plot(history_e1d1.history['loss'])\n",
    "plt.plot(history_e1d1.history['val_loss'])\n",
    "plt.title(\"E1D1 Model Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Valid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Error Analysis for Model 2\n",
    "\n",
    "plt.plot(history_e2d2.history['loss'])\n",
    "plt.plot(history_e2d2.history['val_loss'])\n",
    "plt.title(\"E2D2 Model Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Valid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QisYSkLCoJuC"
   },
   "source": [
    "#### 4.4 Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TeRz6saSJASa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2657032 ,  0.02109489,  0.32228175,  0.10558844,  0.0759377 ,\n",
       "         0.12833036,  0.14161158],\n",
       "       [ 0.27345437,  0.00702652,  0.3591442 ,  0.10409012,  0.07548866,\n",
       "         0.14644086,  0.12828523],\n",
       "       [ 0.27794605, -0.00264779,  0.37958798,  0.10035673,  0.07390881,\n",
       "         0.15313771,  0.11601344],\n",
       "       [ 0.2803792 , -0.00935071,  0.3895485 ,  0.09563474,  0.07207446,\n",
       "         0.15367903,  0.10541991],\n",
       "       [ 0.281516  , -0.01398542,  0.39301184,  0.09072449,  0.07033985,\n",
       "         0.15113805,  0.09664373]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test set using Model 1\n",
    "\n",
    "pred_e1d1=model_e1d1.predict(X_train)\n",
    "pred1_e1d1=model_e1d1.predict(X_test)\n",
    "\n",
    "pred1_e1d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqRGoDgLA_ke",
    "outputId": "ad3848f8-70e1-441a-afa4-da2cba43c2ab",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 111)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(pred1_e1d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.79523224e-01, -1.14984484e-02,  3.70163739e-01,\n",
       "         1.19998299e-01,  8.42699185e-02,  1.18101202e-01,\n",
       "         1.08208962e-01],\n",
       "       [ 2.90278822e-01, -8.14231578e-03,  3.77403378e-01,\n",
       "         1.09127976e-01,  8.37130025e-02,  1.23425938e-01,\n",
       "         1.09710380e-01],\n",
       "       [ 2.99795359e-01, -3.92830651e-03,  3.80104423e-01,\n",
       "         1.01873375e-01,  8.47241208e-02,  1.28427371e-01,\n",
       "         1.11569688e-01],\n",
       "       [ 3.07802916e-01,  1.43837184e-04,  3.80036235e-01,\n",
       "         9.83157679e-02,  8.64914730e-02,  1.32627845e-01,\n",
       "         1.14523672e-01],\n",
       "       [ 3.14246923e-01,  3.57580744e-03,  3.78433228e-01,\n",
       "         9.79799256e-02,  8.84724185e-02,  1.35841385e-01,\n",
       "         1.18861273e-01]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test set using Model 2\n",
    "\n",
    "pred_e2d2=model_e2d2.predict(X_train)\n",
    "pred1_e2d2=model_e2d2.predict(X_test)\n",
    "\n",
    "pred1_e2d2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuL-6375oNuu"
   },
   "source": [
    "#### 4.5 Inverse Scaling of the predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall that we did the Standard Scaling before. Now we need to inverse the data to its orginial scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "kka5WrCVKAFx"
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(train_df.columns):\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    pred1_e1d1[:,:,index]=scaler.inverse_transform(pred1_e1d1[:,:,index])\n",
    "    pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
    "    \n",
    "    pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\n",
    "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    \n",
    "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
    "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-w0gYG-oep8"
   },
   "source": [
    "#### 4.6 Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_ip\n",
      "Day  1 :\n",
      "MAE-E1D1 :  3.4538541141122874, MAE-E2D2 :  3.5570016013513697\n",
      "Day  2 :\n",
      "MAE-E1D1 :  3.443806186761006, MAE-E2D2 :  3.328872085797905\n",
      "Day  3 :\n",
      "MAE-E1D1 :  3.374585578937342, MAE-E2D2 :  3.0911567506223623\n",
      "Day  4 :\n",
      "MAE-E1D1 :  3.2393189078510396, MAE-E2D2 :  2.889867132252986\n",
      "Day  5 :\n",
      "MAE-E1D1 :  3.044686400064147, MAE-E2D2 :  2.7306607347903866\n",
      "\n",
      "\n",
      "avg_time_interval\n",
      "Day  1 :\n",
      "MAE-E1D1 :  0.07111157354493026, MAE-E2D2 :  0.0741373664229223\n",
      "Day  2 :\n",
      "MAE-E1D1 :  0.13826256935106646, MAE-E2D2 :  0.11847214555681342\n",
      "Day  3 :\n",
      "MAE-E1D1 :  0.20616657456549087, MAE-E2D2 :  0.13989420456461388\n",
      "Day  4 :\n",
      "MAE-E1D1 :  0.2708034630459134, MAE-E2D2 :  0.15028173026472036\n",
      "Day  5 :\n",
      "MAE-E1D1 :  0.3495084006007355, MAE-E2D2 :  0.1544444487236514\n",
      "\n",
      "\n",
      "nb_logon\n",
      "Day  1 :\n",
      "MAE-E1D1 :  31801.389351873113, MAE-E2D2 :  31790.423956389473\n",
      "Day  2 :\n",
      "MAE-E1D1 :  31799.39628314028, MAE-E2D2 :  31788.878607721614\n",
      "Day  3 :\n",
      "MAE-E1D1 :  31795.533209470235, MAE-E2D2 :  31785.48719651628\n",
      "Day  4 :\n",
      "MAE-E1D1 :  31795.733719476375, MAE-E2D2 :  31786.13779064216\n",
      "Day  5 :\n",
      "MAE-E1D1 :  31793.86067380999, MAE-E2D2 :  31784.702722228394\n",
      "\n",
      "\n",
      "nb_event_categories\n",
      "Day  1 :\n",
      "MAE-E1D1 :  170.21625075481907, MAE-E2D2 :  167.716707753663\n",
      "Day  2 :\n",
      "MAE-E1D1 :  170.81169616113795, MAE-E2D2 :  169.04529284486676\n",
      "Day  3 :\n",
      "MAE-E1D1 :  171.17629671568918, MAE-E2D2 :  169.9759440894174\n",
      "Day  4 :\n",
      "MAE-E1D1 :  170.97618565228905, MAE-E2D2 :  170.49236175801494\n",
      "Day  5 :\n",
      "MAE-E1D1 :  170.651190271472, MAE-E2D2 :  170.94580876473154\n",
      "\n",
      "\n",
      "nb_domain\n",
      "Day  1 :\n",
      "MAE-E1D1 :  70.38414396153819, MAE-E2D2 :  67.93298437512748\n",
      "Day  2 :\n",
      "MAE-E1D1 :  70.61286406587847, MAE-E2D2 :  68.14799753156039\n",
      "Day  3 :\n",
      "MAE-E1D1 :  71.14538659494703, MAE-E2D2 :  68.5390830630123\n",
      "Day  4 :\n",
      "MAE-E1D1 :  71.25879870901014, MAE-E2D2 :  68.46754790532707\n",
      "Day  5 :\n",
      "MAE-E1D1 :  71.37635316116975, MAE-E2D2 :  68.46156034139123\n",
      "\n",
      "\n",
      "nb_fail_logon\n",
      "Day  1 :\n",
      "MAE-E1D1 :  37.75675888521837, MAE-E2D2 :  37.47381539746086\n",
      "Day  2 :\n",
      "MAE-E1D1 :  37.66539883967673, MAE-E2D2 :  37.33863677600823\n",
      "Day  3 :\n",
      "MAE-E1D1 :  37.24122988764602, MAE-E2D2 :  36.8807575962331\n",
      "Day  4 :\n",
      "MAE-E1D1 :  37.1871496450783, MAE-E2D2 :  36.80762712790234\n",
      "Day  5 :\n",
      "MAE-E1D1 :  36.81122531867263, MAE-E2D2 :  36.46884867696479\n",
      "\n",
      "\n",
      "nb_programs\n",
      "Day  1 :\n",
      "MAE-E1D1 :  1316.309699926931, MAE-E2D2 :  1309.7819323539734\n",
      "Day  2 :\n",
      "MAE-E1D1 :  1319.681416086041, MAE-E2D2 :  1313.7232921949708\n",
      "Day  3 :\n",
      "MAE-E1D1 :  1327.700204783147, MAE-E2D2 :  1321.439543752387\n",
      "Day  4 :\n",
      "MAE-E1D1 :  1326.2347562491598, MAE-E2D2 :  1319.3116750056201\n",
      "Day  5 :\n",
      "MAE-E1D1 :  1334.2418366945026, MAE-E2D2 :  1326.8125819026834\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index,i in enumerate(train_df.columns):\n",
    "  print(i)\n",
    "  for j in range(1,6):\n",
    "    print(\"Day \",j,\":\")\n",
    "    print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,j-1,index],pred1_e1d1[:,j-1,index]),end=\", \")\n",
    "    print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred1_e2d2[:,j-1,index]))\n",
    "  print()\n",
    "  print()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jcim8gUeomHl"
   },
   "source": [
    "From the above output we can observe that in some cases E2D2 model has \n",
    "performed better than E1D1 model with less error. Training different models with different number of stacked layers and creating an ensemble model also performs well. \n",
    "\n",
    "Note: The results vary with respect to the dataset. If we stack more layers it may also lead to overfitting. So the no of layers to be stackes acts as a hyper parameter. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Anomaly Detection - Deep Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "azureml_py38_pt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
